# kernel-continuous-attention

FordA.iPynb has the FordA experiment. More to come. We are stil adding additional documentation for the FordA experiment, but you can run the notebook as is and it will generate some attention densities and f1/accuracies. Change the attention mechanism type (cts/kernel softmax/sparsemax) to the desired one at the top of the file as in the instructions.

If you use this, please cite the Neurips paper:

Alexander Moreno, , Zhenke Wu, Supriya Nagesh, Walter H. Dempsey, and James Matthew Rehg. "Kernel Multimodal Continuous Attention." . In Advances in Neural Information Processing Systems.2022.
